{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e95d73",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e104b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import string\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa3d03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader class\n",
    "class DataLoader:\n",
    "    def __init__(self,dir_name,file_name):\n",
    "        self.dir_name=dir_name\n",
    "        self.file_name = file_name\n",
    "    \n",
    " \n",
    "    def read_csv(self):\n",
    "        os.chdir(self.dir_name)\n",
    "        tweets_df=pd.read_csv(self.file_name)\n",
    "        return tweets_df\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f68cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#object creation\n",
    "DataLoader_obj= DataLoader('../data/','processed_tweet_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4c8b5",
   "metadata": {},
   "source": [
    "# Columns of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44d1c8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>original_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>lang</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>original_author</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun Aug 07 22:31:02 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @benedictrogers: We must not let this happe...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>en</td>\n",
       "      <td>41770</td>\n",
       "      <td>36</td>\n",
       "      <td>GraceCh15554845</td>\n",
       "      <td>207</td>\n",
       "      <td>54</td>\n",
       "      <td>False</td>\n",
       "      <td>['Taiwan']</td>\n",
       "      <td>['benedictrogers']</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sun Aug 07 22:30:35 +0000 2022</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>Wilson Chinonso Blog: Nigerian tribes, the lis...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>wilson_chnns</td>\n",
       "      <td>28</td>\n",
       "      <td>265</td>\n",
       "      <td>False</td>\n",
       "      <td>['China', 'ChinaTaiwan', 'ManUnited']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Imo State Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sun Aug 07 22:30:01 +0000 2022</td>\n",
       "      <td>&lt;a href=\"https://buffer.com\" rel=\"nofollow\"&gt;Bu...</td>\n",
       "      <td>27.89US $ 17% OFF|Usb Condenser Microphone For...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>doos94619918</td>\n",
       "      <td>1936</td>\n",
       "      <td>4792</td>\n",
       "      <td>False</td>\n",
       "      <td>['aliexpress', 'USA', 'uk', 'RT', 'Europe', 'U...</td>\n",
       "      <td>[]</td>\n",
       "      <td>United States New York,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sun Aug 07 22:26:25 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @ChinaInfo777: #PinkFloyd Roger Waters tell...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>91839</td>\n",
       "      <td>5</td>\n",
       "      <td>nhohn2011</td>\n",
       "      <td>870</td>\n",
       "      <td>508</td>\n",
       "      <td>False</td>\n",
       "      <td>['PinkFloyd', 'Taiwan', 'China']</td>\n",
       "      <td>['ChinaInfo777']</td>\n",
       "      <td>Florida, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sun Aug 07 22:25:37 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @WilliamYang120: \"For too long, #Taiwan has...</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>en</td>\n",
       "      <td>46145</td>\n",
       "      <td>84</td>\n",
       "      <td>hoggothoaryhost</td>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>['Taiwan']</td>\n",
       "      <td>['WilliamYang120']</td>\n",
       "      <td>Hong Kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21981</th>\n",
       "      <td>Sat Aug 06 18:04:09 +0000 2022</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>RT @jenniferatntd: Head of #Taiwan's #missile ...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>en</td>\n",
       "      <td>6660</td>\n",
       "      <td>99</td>\n",
       "      <td>threadmaxwhispe</td>\n",
       "      <td>657</td>\n",
       "      <td>864</td>\n",
       "      <td>False</td>\n",
       "      <td>['Taiwan', 'missile']</td>\n",
       "      <td>['jenniferatntd']</td>\n",
       "      <td>Land of Ethan South Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21989</th>\n",
       "      <td>Sat Aug 06 18:03:48 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Minister Wu is crystal clear in his @BBCNews i...</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.419444</td>\n",
       "      <td>en</td>\n",
       "      <td>3129</td>\n",
       "      <td>0</td>\n",
       "      <td>TECO_Toronto</td>\n",
       "      <td>955</td>\n",
       "      <td>202</td>\n",
       "      <td>False</td>\n",
       "      <td>['Taiwan', 'StandWithTaiwan', 'DefendDemocracy']</td>\n",
       "      <td>['BBCNews', 'SpeakerPelosi']</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21990</th>\n",
       "      <td>Sat Aug 06 18:03:47 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @SpokespersonCHN: #PLA Live-fire military d...</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>en</td>\n",
       "      <td>175203</td>\n",
       "      <td>405</td>\n",
       "      <td>mumaralid</td>\n",
       "      <td>1164</td>\n",
       "      <td>605</td>\n",
       "      <td>True</td>\n",
       "      <td>['PLA', 'Taiwan']</td>\n",
       "      <td>['SpokespersonCHN']</td>\n",
       "      <td>Driver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21992</th>\n",
       "      <td>Sat Aug 06 18:03:33 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @jenniferatntd: Head of #Taiwan's #missile ...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>en</td>\n",
       "      <td>14305</td>\n",
       "      <td>99</td>\n",
       "      <td>9thousandbytes</td>\n",
       "      <td>401</td>\n",
       "      <td>858</td>\n",
       "      <td>False</td>\n",
       "      <td>['Taiwan', 'missile']</td>\n",
       "      <td>['jenniferatntd']</td>\n",
       "      <td>Northern Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21996</th>\n",
       "      <td>Sat Aug 06 18:03:27 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @IndoPac_Info: A good infographic of #China...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>en</td>\n",
       "      <td>11538</td>\n",
       "      <td>183</td>\n",
       "      <td>sashalenik</td>\n",
       "      <td>94</td>\n",
       "      <td>1751</td>\n",
       "      <td>False</td>\n",
       "      <td>['China', 'Taiwan', 'ChinaTaiwanCrisis']</td>\n",
       "      <td>['IndoPac_Info']</td>\n",
       "      <td>Gelendzhik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3753 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           created_at  \\\n",
       "5      Sun Aug 07 22:31:02 +0000 2022   \n",
       "11     Sun Aug 07 22:30:35 +0000 2022   \n",
       "19     Sun Aug 07 22:30:01 +0000 2022   \n",
       "36     Sun Aug 07 22:26:25 +0000 2022   \n",
       "39     Sun Aug 07 22:25:37 +0000 2022   \n",
       "...                               ...   \n",
       "21981  Sat Aug 06 18:04:09 +0000 2022   \n",
       "21989  Sat Aug 06 18:03:48 +0000 2022   \n",
       "21990  Sat Aug 06 18:03:47 +0000 2022   \n",
       "21992  Sat Aug 06 18:03:33 +0000 2022   \n",
       "21996  Sat Aug 06 18:03:27 +0000 2022   \n",
       "\n",
       "                                                  source  \\\n",
       "5      <a href=\"http://twitter.com/download/android\" ...   \n",
       "11     <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "19     <a href=\"https://buffer.com\" rel=\"nofollow\">Bu...   \n",
       "36     <a href=\"http://twitter.com/download/android\" ...   \n",
       "39     <a href=\"http://twitter.com/download/android\" ...   \n",
       "...                                                  ...   \n",
       "21981  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "21989  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "21990  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "21992  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "21996  <a href=\"http://twitter.com/download/android\" ...   \n",
       "\n",
       "                                           original_text  polarity  \\\n",
       "5      RT @benedictrogers: We must not let this happe...  0.200000   \n",
       "11     Wilson Chinonso Blog: Nigerian tribes, the lis...  0.000000   \n",
       "19     27.89US $ 17% OFF|Usb Condenser Microphone For...  0.000000   \n",
       "36     RT @ChinaInfo777: #PinkFloyd Roger Waters tell...  0.000000   \n",
       "39     RT @WilliamYang120: \"For too long, #Taiwan has... -0.025000   \n",
       "...                                                  ...       ...   \n",
       "21981  RT @jenniferatntd: Head of #Taiwan's #missile ... -0.200000   \n",
       "21989  Minister Wu is crystal clear in his @BBCNews i...  0.158333   \n",
       "21990  RT @SpokespersonCHN: #PLA Live-fire military d... -0.100000   \n",
       "21992  RT @jenniferatntd: Head of #Taiwan's #missile ... -0.200000   \n",
       "21996  RT @IndoPac_Info: A good infographic of #China...  0.700000   \n",
       "\n",
       "       subjectivity lang  favorite_count  retweet_count  original_author  \\\n",
       "5          0.500000   en           41770             36  GraceCh15554845   \n",
       "11         0.000000   en             134              0     wilson_chnns   \n",
       "19         0.000000   en             265              0     doos94619918   \n",
       "36         0.000000   en           91839              5        nhohn2011   \n",
       "39         0.200000   en           46145             84  hoggothoaryhost   \n",
       "...             ...  ...             ...            ...              ...   \n",
       "21981      0.400000   en            6660             99  threadmaxwhispe   \n",
       "21989      0.419444   en            3129              0     TECO_Toronto   \n",
       "21990      0.250000   en          175203            405        mumaralid   \n",
       "21992      0.400000   en           14305             99   9thousandbytes   \n",
       "21996      0.600000   en           11538            183       sashalenik   \n",
       "\n",
       "       followers_count  friends_count possibly_sensitive  \\\n",
       "5                  207             54              False   \n",
       "11                  28            265              False   \n",
       "19                1936           4792              False   \n",
       "36                 870            508              False   \n",
       "39                  44             60              False   \n",
       "...                ...            ...                ...   \n",
       "21981              657            864              False   \n",
       "21989              955            202              False   \n",
       "21990             1164            605               True   \n",
       "21992              401            858              False   \n",
       "21996               94           1751              False   \n",
       "\n",
       "                                                hashtags  \\\n",
       "5                                             ['Taiwan']   \n",
       "11                 ['China', 'ChinaTaiwan', 'ManUnited']   \n",
       "19     ['aliexpress', 'USA', 'uk', 'RT', 'Europe', 'U...   \n",
       "36                      ['PinkFloyd', 'Taiwan', 'China']   \n",
       "39                                            ['Taiwan']   \n",
       "...                                                  ...   \n",
       "21981                              ['Taiwan', 'missile']   \n",
       "21989   ['Taiwan', 'StandWithTaiwan', 'DefendDemocracy']   \n",
       "21990                                  ['PLA', 'Taiwan']   \n",
       "21992                              ['Taiwan', 'missile']   \n",
       "21996           ['China', 'Taiwan', 'ChinaTaiwanCrisis']   \n",
       "\n",
       "                      user_mentions                         place  \n",
       "5                ['benedictrogers']           Melbourne, Victoria  \n",
       "11                               []             Imo State Nigeria  \n",
       "19                               []      United States New York,   \n",
       "36                 ['ChinaInfo777']                  Florida, USA  \n",
       "39               ['WilliamYang120']                     Hong Kong  \n",
       "...                             ...                           ...  \n",
       "21981             ['jenniferatntd']   Land of Ethan South Dakota   \n",
       "21989  ['BBCNews', 'SpeakerPelosi']               Toronto, Canada  \n",
       "21990           ['SpokespersonCHN']                        Driver  \n",
       "21992             ['jenniferatntd']             Northern Virginia  \n",
       "21996              ['IndoPac_Info']                    Gelendzhik  \n",
       "\n",
       "[3753 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df=DataLoader_obj.read_csv()\n",
    "tweets_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c97d21",
   "metadata": {},
   "source": [
    "# Number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85ff96d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca52fd1",
   "metadata": {},
   "source": [
    "# The first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035386f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>original_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>lang</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>original_author</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Aug 07 22:31:20 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @i_ameztoy: Extra random image (I):\\n\\nLets...</td>\n",
       "      <td>-1.250000e-01</td>\n",
       "      <td>0.190625</td>\n",
       "      <td>en</td>\n",
       "      <td>15760</td>\n",
       "      <td>2</td>\n",
       "      <td>i_ameztoy</td>\n",
       "      <td>20497</td>\n",
       "      <td>2621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['City']</td>\n",
       "      <td>['i_ameztoy']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Aug 07 22:31:16 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @IndoPac_Info: #China's media explains the ...</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>en</td>\n",
       "      <td>6967</td>\n",
       "      <td>201</td>\n",
       "      <td>ZIisq</td>\n",
       "      <td>65</td>\n",
       "      <td>272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['China', 'Taiwan']</td>\n",
       "      <td>['IndoPac_Info']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Aug 07 22:31:07 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>China even cut off communication, they don't a...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>2166</td>\n",
       "      <td>0</td>\n",
       "      <td>Fin21Free</td>\n",
       "      <td>85</td>\n",
       "      <td>392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['XiJinping']</td>\n",
       "      <td>['ZelenskyyUa']</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Aug 07 22:31:06 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Putin to #XiJinping : I told you my friend, Ta...</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>en</td>\n",
       "      <td>2166</td>\n",
       "      <td>0</td>\n",
       "      <td>Fin21Free</td>\n",
       "      <td>85</td>\n",
       "      <td>392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['XiJinping']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Aug 07 22:31:04 +0000 2022</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @ChinaUncensored: I’m sorry, I thought Taiw...</td>\n",
       "      <td>-6.938894e-18</td>\n",
       "      <td>0.556250</td>\n",
       "      <td>en</td>\n",
       "      <td>17247</td>\n",
       "      <td>381</td>\n",
       "      <td>VizziniDolores</td>\n",
       "      <td>910</td>\n",
       "      <td>2608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>['ChinaUncensored']</td>\n",
       "      <td>Ayent, Schweiz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Sun Aug 07 22:31:20 +0000 2022   \n",
       "1  Sun Aug 07 22:31:16 +0000 2022   \n",
       "2  Sun Aug 07 22:31:07 +0000 2022   \n",
       "3  Sun Aug 07 22:31:06 +0000 2022   \n",
       "4  Sun Aug 07 22:31:04 +0000 2022   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                       original_text      polarity  \\\n",
       "0  RT @i_ameztoy: Extra random image (I):\\n\\nLets... -1.250000e-01   \n",
       "1  RT @IndoPac_Info: #China's media explains the ... -1.000000e-01   \n",
       "2  China even cut off communication, they don't a...  0.000000e+00   \n",
       "3  Putin to #XiJinping : I told you my friend, Ta...  1.000000e-01   \n",
       "4  RT @ChinaUncensored: I’m sorry, I thought Taiw... -6.938894e-18   \n",
       "\n",
       "   subjectivity lang  favorite_count  retweet_count original_author  \\\n",
       "0      0.190625   en           15760              2       i_ameztoy   \n",
       "1      0.100000   en            6967            201           ZIisq   \n",
       "2      0.000000   en            2166              0       Fin21Free   \n",
       "3      0.350000   en            2166              0       Fin21Free   \n",
       "4      0.556250   en           17247            381  VizziniDolores   \n",
       "\n",
       "   followers_count  friends_count possibly_sensitive             hashtags  \\\n",
       "0            20497           2621                NaN             ['City']   \n",
       "1               65            272                NaN  ['China', 'Taiwan']   \n",
       "2               85            392                NaN        ['XiJinping']   \n",
       "3               85            392                NaN        ['XiJinping']   \n",
       "4              910           2608                NaN                   []   \n",
       "\n",
       "         user_mentions           place  \n",
       "0        ['i_ameztoy']             NaN  \n",
       "1     ['IndoPac_Info']             NaN  \n",
       "2      ['ZelenskyyUa']     Netherlands  \n",
       "3                   []     Netherlands  \n",
       "4  ['ChinaUncensored']  Ayent, Schweiz  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbad1ec",
   "metadata": {},
   "source": [
    "# Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d7ddada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing value(s) based on columns:\n",
      "created_at                0\n",
      "source                    0\n",
      "original_text             0\n",
      "polarity                  0\n",
      "subjectivity              0\n",
      "lang                      0\n",
      "favorite_count            0\n",
      "retweet_count             0\n",
      "original_author           0\n",
      "followers_count           0\n",
      "friends_count             0\n",
      "possibly_sensitive    15809\n",
      "hashtags                  0\n",
      "user_mentions             0\n",
      "place                  9893\n",
      "dtype: int64\n",
      "The sum of missing value(s) is:\n",
      "25702\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of missing value(s) based on columns:\\n{}\".format(tweets_df.isnull().sum()))\n",
    "print(\"The sum of missing value(s) is:\\n{}\".format(tweets_df.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0305d59",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45649ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231abfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_tweets_dataframe import Clean_Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "607fc3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values \n",
    "processed_tweets = tweets_df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dcb3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    \"\"\"Process tweet function.\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweet: cleaned tweet\n",
    "\n",
    "    \"\"\"\n",
    "    # remove hashtags\n",
    "    tweet = re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet)\n",
    "    # remove @ handles\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks    \n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "004b91d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaner(df: pd.DataFrame, save=False) -> pd.DataFrame:\n",
    "    \"\"\"Data Cleaner Function.\n",
    "    Input:\n",
    "        df: Pandas Dataframe\n",
    "        save: Boolean value\n",
    "    Output:\n",
    "        df: Cleaned Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    Tweet_cleaner = Clean_Tweets(df)\n",
    "    df = Tweet_cleaner.remove_non_english_tweets(df)\n",
    "    df = Tweet_cleaner.drop_duplicate(df)\n",
    "    df = Tweet_cleaner.drop_unwanted_column(df)\n",
    "    df = Tweet_cleaner.drop_unwanted_column(df)\n",
    "    df = Tweet_cleaner.convert_to_datetime(df)\n",
    "    df = Tweet_cleaner.convert_to_numbers(df)\n",
    "    df['clean_text'] = df['original_text'].apply(process_tweet)\n",
    "    df['clean_text'] =  df['clean_text'].astype(str)\n",
    "    df['clean_text'] = df['clean_text'].apply(lambda x: x.lower())\n",
    "    df['clean_text']= df['clean_text'].apply(lambda x: x.translate(str.maketrans(' ', ' ', string.punctuation)))\n",
    "\n",
    "\n",
    "    if save:\n",
    "        try: \n",
    "            df.to_csv('../data/cleaned_tweet_data.csv', index=False)\n",
    "            \n",
    "            print('File Successfully Saved.!!!')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Save failed...\",e)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "712cead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automation in Action...!!!\n",
      "File Successfully Saved.!!!\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = data_cleaner(tweets_df, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "072945ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21997 entries, 0 to 21999\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype              \n",
      "---  ------              --------------  -----              \n",
      " 0   created_at          21997 non-null  datetime64[ns, UTC]\n",
      " 1   source              21997 non-null  object             \n",
      " 2   original_text       21997 non-null  object             \n",
      " 3   polarity            21997 non-null  float64            \n",
      " 4   subjectivity        21997 non-null  float64            \n",
      " 5   lang                21997 non-null  object             \n",
      " 6   favorite_count      21997 non-null  int64              \n",
      " 7   retweet_count       21997 non-null  int64              \n",
      " 8   original_author     21997 non-null  object             \n",
      " 9   followers_count     21997 non-null  int64              \n",
      " 10  friends_count       21997 non-null  int64              \n",
      " 11  possibly_sensitive  6190 non-null   object             \n",
      " 12  hashtags            21997 non-null  object             \n",
      " 13  user_mentions       21997 non-null  object             \n",
      " 14  place               12106 non-null  object             \n",
      " 15  clean_text          21997 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), int64(4), object(9)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380fa89b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e62b4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [tweet for tweet in cleaned_df['clean_text'].head()]\n",
    "word_list = [sent.split() for sent in sentence_list]\n",
    "\n",
    "word_to_id = corpora.Dictionary(word_list) #generate unique tokens\n",
    "    \n",
    "corpus= [word_to_id.doc2bow(tweet) for tweet in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8422c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)], [(7, 2), (10, 1), (15, 5), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1)], [(15, 2), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 2), (53, 1)], [(5, 2), (15, 1), (35, 1), (52, 2), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 2)], [(5, 1), (27, 1), (60, 1), (70, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16aa84c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_words = [[(word_to_id[id], count) for id, count in line] for line in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74a00001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('coast', 1), ('district', 1), ('extra', 1), ('focus', 1), ('gt', 1), ('i', 1), ('image', 1), ('in', 1), ('lets', 1), ('longjing', 1), ('of', 1), ('one', 1), ('random', 1), ('specific', 1), ('taichung', 1), ('the', 1), ('very', 1), ('western', 1), ('zone', 1), ('…', 1)], [('in', 2), ('of', 1), ('the', 5), ('area', 1), ('drills', 1), ('each', 1), ('explains', 1), ('for', 1), ('labels', 1), ('media', 1), ('military', 1), ('pi…', 1), ('read', 1), ('reasons', 1), ('s', 1), ('strait', 1)], [('the', 2), ('anwer', 1), ('ask', 1), ('but', 1), ('change', 1), ('china', 1), ('clown', 1), ('communication', 1), ('cut', 1), ('dont', 1), ('enters', 1), ('even', 1), ('from', 1), ('here', 1), ('mind', 1), ('off', 1), ('phonecalls', 1), ('putins', 1), ('stage', 1), ('they', 1), ('to', 2), ('us', 1)], [('i', 2), ('the', 1), ('but', 1), ('to', 2), ('a', 1), ('be', 1), ('chinas', 1), ('eyes', 1), ('friend', 1), ('including', 1), ('it', 1), ('like', 1), ('model', 1), ('much', 1), ('my', 1), ('nukes', 1), ('open', 1), ('pelosi', 1), ('putin', 1), ('state', 1), ('taiwan', 1), ('told', 1), ('took', 1), ('ukrainian', 1), ('vassal', 1), ('warned', 1), ('will', 1), ('you', 2)], [('i', 1), ('military', 1), ('it', 1), ('taiwan', 1), ('an', 1), ('because', 1), ('country', 1), ('currency', 1), ('d…', 1), ('government', 1), ('had', 1), ('independent', 1), ('its', 1), ('i’m', 1), ('own', 1), ('sorry', 1), ('thought', 1), ('travel', 1), ('was', 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(id_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c541f5",
   "metadata": {},
   "source": [
    "# Topic Modeling using Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f44b2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "                                           id2word=word_to_id ,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1f1c110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.032*\"own\" + 0.032*\"country\" + 0.032*\"i\" + 0.032*\"was\" + 0.032*\"had\" + '\n",
      "  '0.032*\"military\" + 0.032*\"it\" + 0.032*\"government\" + 0.032*\"independent\" + '\n",
      "  '0.032*\"because\"'),\n",
      " (1,\n",
      "  '0.088*\"the\" + 0.031*\"to\" + 0.031*\"in\" + 0.031*\"you\" + 0.031*\"i\" + '\n",
      "  '0.017*\"but\" + 0.017*\"of\" + 0.017*\"military\" + 0.017*\"strait\" + '\n",
      "  '0.017*\"area\"'),\n",
      " (2,\n",
      "  '0.011*\"of\" + 0.011*\"specific\" + 0.011*\"extra\" + 0.011*\"gt\" + 0.011*\"i\" + '\n",
      "  '0.011*\"very\" + 0.011*\"one\" + 0.011*\"in\" + 0.011*\"lets\" + 0.011*\"the\"'),\n",
      " (3,\n",
      "  '0.031*\"district\" + 0.031*\"western\" + 0.031*\"coast\" + 0.031*\"taichung\" + '\n",
      "  '0.031*\"zone\" + 0.031*\"…\" + 0.031*\"image\" + 0.031*\"longjing\" + 0.031*\"very\" '\n",
      "  '+ 0.031*\"one\"'),\n",
      " (4,\n",
      "  '0.052*\"to\" + 0.051*\"the\" + 0.028*\"even\" + 0.028*\"clown\" + 0.028*\"but\" + '\n",
      "  '0.028*\"dont\" + 0.028*\"stage\" + 0.028*\"china\" + 0.028*\"ask\" + 0.028*\"anwer\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fabecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('own', 0.03184627),\n",
      "   ('country', 0.031842645),\n",
      "   ('i', 0.03183027),\n",
      "   ('was', 0.031825766),\n",
      "   ('had', 0.031823944),\n",
      "   ('military', 0.03182359),\n",
      "   ('it', 0.03181817),\n",
      "   ('government', 0.031813342),\n",
      "   ('independent', 0.03181118),\n",
      "   ('because', 0.031810854)]),\n",
      " (1,\n",
      "  [('the', 0.08784842),\n",
      "   ('to', 0.031160245),\n",
      "   ('in', 0.03115323),\n",
      "   ('you', 0.031130059),\n",
      "   ('i', 0.031121919),\n",
      "   ('but', 0.017011398),\n",
      "   ('of', 0.016992591),\n",
      "   ('military', 0.016992526),\n",
      "   ('strait', 0.016992446),\n",
      "   ('area', 0.016992433)]),\n",
      " (2,\n",
      "  [('of', 0.010845418),\n",
      "   ('specific', 0.0108450465),\n",
      "   ('extra', 0.0108443005),\n",
      "   ('gt', 0.0108314),\n",
      "   ('i', 0.010830623),\n",
      "   ('very', 0.010830491),\n",
      "   ('one', 0.010829565),\n",
      "   ('in', 0.010828993),\n",
      "   ('lets', 0.0108260065),\n",
      "   ('the', 0.010825024)]),\n",
      " (3,\n",
      "  [('district', 0.031089652),\n",
      "   ('western', 0.031071771),\n",
      "   ('coast', 0.031071125),\n",
      "   ('taichung', 0.031069558),\n",
      "   ('zone', 0.03106355),\n",
      "   ('…', 0.031062469),\n",
      "   ('image', 0.03106179),\n",
      "   ('longjing', 0.031060511),\n",
      "   ('very', 0.031058747),\n",
      "   ('one', 0.031058569)]),\n",
      " (4,\n",
      "  [('to', 0.05153114),\n",
      "   ('the', 0.051447846),\n",
      "   ('even', 0.028085068),\n",
      "   ('clown', 0.028084222),\n",
      "   ('but', 0.028083825),\n",
      "   ('dont', 0.02808251),\n",
      "   ('stage', 0.028079284),\n",
      "   ('china', 0.028077656),\n",
      "   ('ask', 0.02807649),\n",
      "   ('anwer', 0.028069047)])]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57403e",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03c4dbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -5.003623516922412\n",
      "\n",
      " Ldamodel Coherence Score/Accuracy on Tweets:  0.8676158450606035\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "\n",
    "#It's a measure of how good the model is. The lower the better. Perplexity is a negative value\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "doc_lda = lda_model[corpus]\n",
    "\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=word_to_id, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\n Ldamodel Coherence Score/Accuracy on Tweets: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a62ffac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m419.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: gensim in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from pyLDAvis) (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from pyLDAvis) (1.23.1)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from pyLDAvis) (1.4.3)\n",
      "Requirement already satisfied: jinja2 in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from pyLDAvis) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from pyLDAvis) (61.2.0)\n",
      "Requirement already satisfied: scipy in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from pyLDAvis) (1.9.0)\n",
      "Requirement already satisfied: joblib in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from pyLDAvis) (1.1.0)\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.3/381.3 kB\u001b[0m \u001b[31m321.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m321.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting future\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting funcy\n",
      "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m349.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from pandas>=1.2.0->pyLDAvis) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from gensim->pyLDAvis) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from jinja2->pyLDAvis) (2.1.1)\n",
      "Requirement already satisfied: packaging in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from numexpr->pyLDAvis) (21.3)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/hmicheal/.conda/envs/10x/lib/python3.10/site-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n",
      "Building wheels for collected packages: pyLDAvis, future, sklearn\n",
      "  Building wheel for pyLDAvis (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136882 sha256=e28c818e9ff8b11ac3c34f03e2d01325b6b4a210e67d51a00a15155573741b51\n",
      "  Stored in directory: /home/hmicheal/.cache/pip/wheels/e9/95/74/4766157910829d2fbc6b913850a62cfd15da77a199302cdf9c\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=11a60c4d79175bce6c9e7c27f071173441c3b15459bfdf468c7406ea49ffd976\n",
      "  Stored in directory: /home/hmicheal/.cache/pip/wheels/22/73/06/557dc4f4ef68179b9d763930d6eec26b88ed7c389b19588a1c\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=779186bd53bd7cabc9d87f24331b145557232297fd419887e402b72ded7f33bc\n",
      "  Stored in directory: /home/hmicheal/.cache/pip/wheels/9b/13/01/6f3a7fd641f90e1f6c8c7cded057f3394f451f340371c68f3d\n",
      "Successfully built pyLDAvis future sklearn\n",
      "Installing collected packages: funcy, threadpoolctl, future, scikit-learn, numexpr, sklearn, pyLDAvis\n",
      "Successfully installed funcy-1.17 future-0.18.2 numexpr-2.8.3 pyLDAvis-3.3.1 scikit-learn-1.1.2 sklearn-0.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e2d904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
